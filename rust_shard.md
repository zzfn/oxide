## 文章框架

### 1. 引言 (Introduction)

#### 为什么复刻 Claude Code？

第一次使用 Claude Code 时，我被它那种"所想即所得"的流畅体验深深震撼。不需要切换编辑器、不需要复制粘贴、不需要频繁的上下文切换——只需要在终端中描述需求，AI 就能自主地读取代码、执行命令、修改文件，并将结果实时反馈。

但更让我着迷的是它背后的设计：**一个能够理解意图、规划任务、执行操作、观察结果、并持续迭代的智能 Agent**。这不是简单的"调用 API 返回结果"，而是一个完整的认知循环——这正是我想深入理解的核心。

最好的学习方式就是动手实现。通过复刻 Claude Code，我能够：

- **理解 Agent 核心机制**：如何设计"思考-行动-观察"循环？如何处理 Tool Call 的解析与执行？
- **掌握工程实践**：如何管理上下文、如何处理流式输出、如何设计权限系统？
- **探索技术选型**：不同语言在实现 Agent 时有什么 trade-off？

#### 为什么选择 Rust？

坦白说，选择 Rust 的原因很简单粗暴：

1. **听说它很快** —— 各种 benchmarks 上 Rust 总是名列前茅，零成本抽象、内存安全这些标签深入人心
2. **我完全不会 Rust** —— 这才是关键！对于一个以"学习 Agent"为目标的项目，还有什么比用一门陌生语言、让 AI 辅助从头实现更刺激的？

这听起来有点疯狂：用我不熟悉的语言，构建一个我还没完全理解概念的复杂系统。但正是这种"双重未知"的状态，让项目变得有趣：

- **AI 是我的导师**：每当我卡在所有权、借用检查器、生命周期这些概念上时，Claude 就会耐心解释，并给出正确的代码
- **边学边用**：不是先啃完《Rust 程序设计语言》再动手，而是直接上手，遇到问题就问 AI
- **真实的实践**：不是写toy example，而是构建一个真实可用的系统

在这个过程中，我确实体会到了 Rust 的优势：

- **类型系统帮我避坑**：Agent 的状态流转用 `enum` 建模后，编译器会强制我处理所有可能的分支
- **错误处理很清晰**：`Result<T, E>` 和 `?` 操作符让错误传播变得显式且可追踪
- **性能确实强**：编译后的单一二进制，启动即用，内存占用也远低于 Python 实现

但这都是后话了。最开始的想法其实很简单：**用 AI 辅助，以 Rust 实现 Claude Code，从而深入学习 Agent 的核心机制**。

#### 核心目标：通过复刻理解 Agent 架构

Claude Code 不仅仅是一个"聪明的 CLI 工具"，它是一个精心设计的 AI Agent 系统。我的目标是通过复刻它，理解这些核心概念：

- **Agent 的决策循环**：如何设计"思考-行动-观察"的闭环？如何在多次迭代中保持目标一致？
- **记忆管理**：短期记忆（对话历史）和长期记忆（代码库上下文）如何组织？Token 有限时如何做上下文压缩？
- **Tool 的调用协调**：如何定义 Tool 接口？如何让 LLM 理解并正确调用？如何处理 Tool 执行失败的情况？
- **权限与安全**：如何在自动化和用户控制之间取得平衡？如何设计可干预的执行流程？
- **流式响应处理**：如何实时渲染 LLM 的输出？如何在 Tool 执行时保持界面的响应性？

这不是为了造一个"更好"的轮子，而是为了**拆解一个成熟的轮子，理解它为什么这样设计**。在这个过程中，Rust 是实现语言，AI 是辅助工具，真正的目标是掌握构建 Agent 系统的思维和方法。

本文将记录我从零开始复刻 Claude Code 的完整过程——从架构设计到核心实现，从遇到的坑到最终的解决方案。如果你想了解 Agent 的工作原理，或者好奇如何用 AI 辅助学习一门新语言并构建复杂系统，希望这篇文章能给你一些启发。
    

### 2. 系统架构设计 (Architecture)

- **核心循环 (The Agent Loop)：** 解释 Agent 如何处理任务。

```
用户输入 (User Input)
    │
    ▼
┌─────────────────────────────────────────────────────────────┐
│                     Input Processor                          │
│  - 解析用户指令                                              │
│  - 检查权限边界                                              │
│  - 构建初始上下文                                            │
└─────────────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────────────┐
│                    Orchestrator (大脑)                       │
│  ┌─────────────────────────────────────────────────────┐    │
│  │  1. 调用 LLM (Anthropic API)                         │    │
│  │  2. 接收流式响应 (Streaming Response)                │    │
│  │  3. 解析 Tool Call (JSON/XML)                        │    │
│  └─────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────┘
    │
    ▼
    有 Tool Call？
    │
    ├─── NO ──▶ 直接输出 LLM 响应 ──▶ 结束
    │
    └─── YES ─────────────────────────────────┐
                                                ▼
        ┌───────────────────────────────────────────────────┐
        │              Toolbox (工具箱)                      │
        │  ┌────────────┐  ┌────────────┐  ┌────────────┐  │
        │  │ File Tool  │  │ Shell Tool │  │ Search Tool│  │
        │  │ (Read/Write)│  │ (Exec/Bash)│  │ (Grep/Glob)│  │
        │  └────────────┘  └────────────┘  └────────────┘  │
        │                                                   │
        │  - 权限确认 (Prompt User)                          │
        │  - 执行操作                                         │
        │  - 收集结果                                         │
        └───────────────────────────────────────────────────┘
                        │
                        ▼
                ┌───────────────────┐
                │  UI/UX 层反馈      │
                │  - 实时渲染输出     │
                │  - 显示执行状态     │
                └───────────────────┘
                        │
                        ▼
            将 Tool 结果注入上下文 ──▶ 回到 Orchestrator (循环)
                                              │
                                              ▼
                                    达到目标/最大迭代次数？
                                              │
                         ┌────────────────────┼────────────────────┐
                         │                    │                    │
                        YES                  NO                   YES
                         │                    │                    │
                         ▼                    ▼                    ▼
                    输出最终结果        继续下一轮思考          用户主动终止
```

**关键特性：**
- **流式响应**：LLM 输出实时渲染，不等待完整响应
- **权限中断**：Tool 执行前可暂停等待用户确认
- **错误恢复**：Tool 失败时将错误信息反馈给 LLM 自我修正
- **上下文累积**：每轮对话历史、Tool 结果都会注入下一轮

- **模块化拆分：**

    - **Input Processor:** 处理用户指令。

    - **Orchestrator (大脑):** 负责调用 LLM，解析 Tool Call。

    - **Toolbox (工具箱):** 文件读写、终端命令执行、代码搜索。

    - **UI/UX 层:** 终端交互界面。
        

### 3. 开发环境与工具链 (Development Environment)

#### 基础环境配置

- **硬件**: M1 MacBook Pro
- **系统**: macOS (Darwin 24.1.0)
- **Rust 安装**: `brew install rust` （通过 Homebrew 管理，版本 1.75+）
- **包管理**: Cargo 工作空间（Workspace）管理多 crate 项目结构

就这些，非常简单。没有复杂的工具链配置，开箱即用。

#### AI 辅助工具组合

我的工具组合如下：

- **Claude Code (GLM-4.7 编码套餐)**: 处理基础开发任务
  - 文件读写、目录遍历、代码搜索等常规操作
  - 简单的代码生成和重构
  - Git 提交、依赖管理

- **Antigravity (Claude Opus)**: 复杂逻辑和架构设计
  - 核心数据结构设计（如 Agent 状态机、Tool 接口）
  - 异步流程编排和错误处理策略
  - 性能优化建议和架构改进

- **Codex**: 修 Bug 和解决疑难杂症
  - 借用检查器报错的根因分析
  - 复杂类型推断和生命周期标注
  - 编译器警告的修复方案

**AI 使用策略**:
- **概念解释**: 所有权、生命周期、trait 等 Rust 独特概念，直接问 AI 比查文档更快
- **错误诊断**: 编译器报错时，复制完整错误信息让 AI 分析根因
- **代码审查**: 每完成一个模块，让 AI 检查是否符合 Rust 最佳实践

#### 开发工作流

```
1. openspec proposal - 创建变更提案，规划功能架构
2. openspec apply - 应用提案到代码库（自动生成/修改文件）
3. cargo check - 快速检查语法
4. cargo test - 运行单元测试
5. cargo clippy - 静态分析（AI 会修复所有警告）
6. cargo fmt - 格式化（保持代码风格一致）
7. git commit - 提交代码
```

**openspec 的核心价值**：
- 所有功能开发都先经过提案阶段，强制思考架构设计
- 提案应用后自动生成代码骨架，减少手工编写
- 提案文档化，便于后续回顾和维护

#### 踩坑记录与解决方案

- **M1 Mac 芯片兼容性**: 某些原生依赖（如 `regex` 的 SIMD 优化）需要特殊编译标志
- **首次编译时间**: Cargo 的依赖编译可能耗时 10-30 分钟，使用 `sccache` 缓存加速
- **rust-analyzer 配置**: 在工作空间下需正确配置 `linkedProjects`，否则智能提示不完整
- **终端库兼容性**: `crossterm` vs `termion` 的选择，前者跨平台但体积大，后者轻量但仅 Unix

这个章节的价值在于：**让读者看到 AI 辅助编程的真实工作流，以及如何高效地从零上手 Rust 开发**。

---

### 4. 核心技术栈 (The Rust Stack)

- **异步运行：** `tokio` (高性能 I/O)。

- **LLM 交互：** `rig-core` (统一的 LLM 抽象层，支持多模型)。

- **界面 UI：** `termimad` (Markdown 渲染)、`crossterm` (终端控制)、`inquire` (交互式提示)、`reedline` (命令行编辑)。

- **代码处理：** `walkdir` (目录遍历)、`ignore` (过滤 .gitignore)、`grep-searcher` (代码搜索)、`regex` (正则匹配)。

- **序列化：** `serde` 系列 (JSON/YAML/TOML 配置支持)。

- **其他工具：** `anyhow`/`thiserror` (错误处理)、`chrono` (时间处理)、`git2` (Git 集成)、`tiktoken-rs` (Token 计数)。
    

### 5. 关键功能实现 (Deep Dives)

#### A. 提示词工程与状态机

- 如何构建 System Prompt，让 LLM 稳定输出指定的 Tool Call 格式（通常是 JSON 或特定 XML）。
    
- 使用 Rust 的 `enum` 和 `match` 完美处理 Agent 的状态流转。
    

#### B. 权限与安全边界 (Permission System)

- 复刻 Claude Code 的核心：**执行命令前的用户确认机制**。
    
- 如何在 Rust 中捕获终端输出并实时流式反馈给 LLM。
    

#### C. 上下文管理与 Token 优化

- 如何处理大文件的读取？（不仅仅是读取全文，而是提取摘要或相关片段）。
    
- **RAG 的引入：** 使用 `text-splitter` 库进行代码切片。
    

### 6. 挑战与解决方案 (Challenges)

- **处理流式响应：** 如何在终端实时渲染 LLM 的 Markdown 输出（推荐 `glow` 或 `termimad`）。
    
- **错误恢复：** 当 Tool 执行失败时，如何让 Agent 自我修正。
    

### 7. 演示与性能对比 (Demo & Performance)

- 展示复刻版的运行截图或动图。
    
- 对比 Python/JS 版本的启动速度与内存占用（展示 Rust 的原生优势）。
    

### 8. 结语与未来展望

- 后续计划：增加 LSP 集成、支持更多模型（如 DeepSeek）、更强的多文件协同能力。
    
- 对 Rust 在 AI 生态中位置的思考。
    

